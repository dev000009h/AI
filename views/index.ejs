<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>VMS ‚Äì Video Management System</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@latest/dist/face-api.min.js"></script>
  <style>
    :root { --green:#00ff88; --orange:#ffa500; --danger:#ef4444; --ink:#111; }
    * { box-sizing: border-box; }
    body { margin:0; font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial; background:#000; color:#fff; }
    .wrap { max-width:1100px; margin:0 auto; padding:18px; }
    .row { display:grid; grid-template-columns: 1.2fr 1fr; gap:20px; }
    .card { background:#111; border:1px solid #222; border-radius:12px; padding:18px; }
    h1 { font-weight:300; color:var(--green); letter-spacing:2px; margin:0 0 10px; }
    .controls { display:flex; gap:10px; align-items:center; margin-bottom:14px; }
    select, .btn { border-radius:8px; border:1px solid #333; background:#1b1b1b; color:#fff; padding:8px 12px; }
    .btn { cursor:pointer; transition:.2s; }
    .btn:hover { filter:brightness(1.1); }
    .btn-primary { background:var(--green); color:#000; border-color:#00c66b; }
    .btn-danger { background:rgba(239,68,68,.2); border-color:#ef4444; color:#ef4444; }
    .status { padding:10px 12px; border-radius:8px; font-size:.95rem; margin:10px 0 0; display:none; }
    .status.info { background:#0f172a; color:#9ca3af; }
    .status.success { background:rgba(16,185,129,.15); color:#34d399; }
    .status.error { background:rgba(239,68,68,.15); color:#f87171; }
    .progress { background:#222; height:10px; border-radius:6px; overflow:hidden; }
    .bar { height:100%; width:0%; background:#3b82f6; transition:width .1s linear; }
    .grid2 { display:grid; grid-template-columns: 1fr auto; gap:16px; align-items:start; }
    .video-shell { position:relative; width:400px; height:300px; margin:auto; border-radius:10px; overflow:hidden; background:#000; }
    video, canvas { position:absolute; inset:0; width:100%; height:100%; display:none; }
    .hint { text-align:center; color:#9ca3af; margin-top:8px; font-size:.9rem; }
    .counter { position:absolute; left:8px; top:8px; font:600 12px/1 system-ui, Arial; background:rgba(0,0,0,.55); padding:6px 8px; border-radius:6px; color:var(--green); }
    .header { display:flex; justify-content:space-between; align-items:center; }
    .small { opacity:.75; font-size:.9rem; }
  </style>
</head>
<body>
<div class="wrap">
  <div class="header">
    <h1>VMS</h1>
    <div class="controls">
      <select id="cameraSelect"><option>Loading cameras‚Ä¶</option></select>
      <button class="btn" id="flipCam">üì∑ Flip</button>
      <button class="btn" id="manageBtn">‚öôÔ∏è Manage (stub)</button>
    </div>
  </div>

  <div class="row">
    <!-- Live recognition area (optional/kept simple) -->
    <div class="card">
      <h2 style="margin:0 0 10px;">Live View</h2>
      <div class="video-shell" style="max-width:640px; height:360px;">
        <video id="mainVideo" autoplay playsinline muted></video>
        <canvas id="mainOverlay"></canvas>
      </div>
      <div class="small" id="liveInfo">Status: waiting for camera‚Ä¶</div>
    </div>

    <!-- Registration card (based on your reference, but robust) -->
    <div class="card">
      <h2 style="text-align:center; margin:0 0 16px; color:#e5e7eb;">Register New User</h2>
      <div class="grid2">
        <div>
          <div class="form-group" style="margin-bottom:10px;">
            <label for="regName">Full Name</label>
            <input id="regName" placeholder="Enter full name" style="width:100%; margin-top:6px;" />
          </div>

          <div style="display:flex; gap:8px; margin:10px 0;">
            <button id="startRegistration" class="btn btn-primary">Start Camera & Registration</button>
            <button id="stopRegistration" class="btn btn-danger" style="display:none;">Stop</button>
          </div>

          <div id="registrationStatus" class="status info">Initializing‚Ä¶</div>

          <div id="captureWrap" style="display:none; margin-top:12px;">
            <div class="progress"><div id="progressBar" class="bar"></div></div>
            <p class="hint">Capturing facial data‚Ä¶ <span id="timeRemaining">5</span> seconds remaining</p>
          </div>
        </div>

        <div>
          <div class="video-shell">
            <div id="samplesCounter" class="counter" style="display:none;">Samples: 0</div>
            <video id="regVideo" width="400" height="300" autoplay playsinline muted></video>
            <canvas id="regOverlay" width="400" height="300"></canvas>
          </div>
          <p class="hint">Keep your face well lit and centered. The green mask should hug your face.</p>
        </div>
      </div>
    </div>
  </div>
</div>

<script>
/* -------------------- Globals -------------------- */
let cameras = [];
let currentCam = 0;
let mainStream = null;

let mainVideo, mainOverlay, mainCtx;
let regVideo, regOverlay, regCtx;

let modelsLoaded = false;
let detectLiveTimer = null;

let isRegistering = false;
let regSamples = [];
let regProgressTimer = null;

const MODEL_URL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api@latest/model/';

/* -------------------- Utils -------------------- */
const qs  = (s) => document.querySelector(s);
const qsa = (s) => Array.from(document.querySelectorAll(s));

function setStatus(el, message, type='info') {
  el.textContent = message;
  el.className = `status ${type}`;
  el.style.display = 'block';
}

/* -------------------- Model load -------------------- */
async function loadModels() {
  await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
  await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
  await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
  await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
  modelsLoaded = true;
}

/* -------------------- Camera helpers -------------------- */
async function listCameras() {
  const devices = await navigator.mediaDevices.enumerateDevices();
  cameras = devices.filter(d => d.kind === 'videoinput');
  const sel = qs('#cameraSelect');
  sel.innerHTML = '';
  if (!cameras.length) {
    sel.innerHTML = '<option>No cameras found</option>';
    return;
  }
  cameras.forEach((cam, i) => {
    const opt = document.createElement('option');
    opt.value = i;
    opt.textContent = cam.label || `Camera ${i + 1}`;
    sel.appendChild(opt);
  });
  sel.value = currentCam;
}

async function startStream(videoEl, width=640, height=360) {
  if (mainStream) mainStream.getTracks().forEach(t => t.stop());
  mainStream = await navigator.mediaDevices.getUserMedia({
    video: {
      deviceId: cameras[currentCam]?.deviceId,
      width: { ideal: width }, height: { ideal: height }, frameRate: { ideal: 15, max: 30 }
    }
  });
  videoEl.srcObject = mainStream;
  return new Promise((res) => videoEl.onloadedmetadata = res);
}

/* -------------------- Live view (left) -------------------- */
async function startLive() {
  const info = qs('#liveInfo');
  try {
    await startStream(mainVideo, 640, 360);
    mainOverlay.width = mainVideo.videoWidth;
    mainOverlay.height = mainVideo.videoHeight;
    mainVideo.style.display = 'block';
    mainOverlay.style.display = 'block';
    info.textContent = 'Live: camera active';
    loopLive();
  } catch (e) {
    info.textContent = 'Failed to start camera (live). Check permissions or HTTPS.';
  }
}

async function loopLive() {
  if (!modelsLoaded || !mainVideo.srcObject) {
    detectLiveTimer = setTimeout(loopLive, 300);
    return;
  }
  try {
    const dets = await faceapi
      .detectAllFaces(mainVideo, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5, maxResults: 5 }))
      .withFaceLandmarks()
      .withFaceDescriptors();

    mainCtx.clearRect(0, 0, mainOverlay.width, mainOverlay.height);
    if (dets.length) {
      const scaled = faceapi.resizeResults(dets, { width: mainOverlay.width, height: mainOverlay.height });
      faceapi.draw.drawDetections(mainOverlay, scaled);
      faceapi.draw.drawFaceLandmarks(mainOverlay, scaled);
    }
  } catch (e) {
    // swallow occasional decode errors
  }
  detectLiveTimer = setTimeout(loopLive, 120);
}

/* -------------------- Registration flow (right) -------------------- */
function drawFaceMaskFromLandmarks(positions, ctx, canvas) {
  // indices: 0‚Äì16 jaw, 17‚Äì21 left brow, 22‚Äì26 right brow
  const jaw = positions.slice(0,17);
  const leftBrow = positions.slice(17,22);
  const rightBrow = positions.slice(22,27);
  const path = new Path2D();
  path.moveTo(jaw[0].x, jaw[0].y);
  for (let i=1;i<jaw.length;i++) path.lineTo(jaw[i].x, jaw[i].y);
  [...rightBrow, ...leftBrow.slice().reverse()].forEach(p => path.lineTo(p.x, p.y));
  path.closePath();

  ctx.save();
  ctx.fillStyle = 'rgba(0,0,0,.55)';
  ctx.fillRect(0,0,canvas.width,canvas.height);
  ctx.globalCompositeOperation='destination-out';
  ctx.fillStyle='#000'; ctx.fill(path);
  ctx.globalCompositeOperation='source-over';
  ctx.strokeStyle = '#00ff88'; ctx.lineWidth = 2; ctx.stroke(path);
  ctx.restore();
}

async function startRegistrationFlow() {
  const name = qs('#regName').value.trim();
  const status = qs('#registrationStatus');
  if (!name) return setStatus(status, 'Please enter your full name first.', 'error');
  if (!modelsLoaded) return setStatus(status, 'Models are still loading. Please wait‚Ä¶', 'error');

  try {
    setStatus(status, 'Starting camera‚Ä¶', 'info');
    await startStream(regVideo, 400, 300);
    regOverlay.width = regVideo.videoWidth || 400;
    regOverlay.height = regVideo.videoHeight || 300;
    regVideo.style.display = 'block';
    regOverlay.style.display = 'block';
    qs('#samplesCounter').style.display = 'block';

    setStatus(status, 'Camera ready. Keep face centered. Capture starts shortly‚Ä¶', 'success');

    // start detection loop immediately
    regSamples = [];
    isRegistering = false;
    loopRegistrationDetect();

    // start capture after 1s warmup
    setTimeout(() => beginCapture(), 1000);
  } catch (e) {
    console.error(e);
    setStatus(status, 'Failed to access camera. Use HTTPS/localhost and allow permissions.', 'error');
  }
}

function beginCapture() {
  const status = qs('#registrationStatus');
  const bar = qs('#progressBar');
  const wrap = qs('#captureWrap');
  const timeEl = qs('#timeRemaining');

  isRegistering = true;
  setStatus(status, 'Capturing facial data‚Ä¶ keep steady & look at camera.', 'info');
  wrap.style.display = 'block';
  bar.style.width = '0%';
  timeEl.textContent = '5';

  let ms = 0;
  clearInterval(regProgressTimer);
  regProgressTimer = setInterval(() => {
    ms += 100;
    const pct = Math.min(ms / 5000 * 100, 100);
    bar.style.width = pct + '%';
    timeEl.textContent = Math.max(0, Math.ceil((5000 - ms)/1000));
    if (ms >= 5000) {
      clearInterval(regProgressTimer);
      completeRegistration();
    }
  }, 100);

  // buttons UI
  qs('#startRegistration').style.display = 'none';
  qs('#stopRegistration').style.display = 'inline-block';
}

function stopRegistrationFlow() {
  isRegistering = false;
  clearInterval(regProgressTimer);
  qs('#captureWrap').style.display = 'none';
  qs('#stopRegistration').style.display = 'none';
  qs('#startRegistration').style.display = 'inline-block';
  setStatus(qs('#registrationStatus'), 'Registration stopped.', 'info');

  // stop camera dedicated to reg card (we‚Äôre sharing main stream; just detach)
  if (regVideo?.srcObject) regVideo.srcObject = null;
  regVideo.style.display = 'none';
  regOverlay.style.display = 'none';
  qs('#samplesCounter').style.display = 'none';
}

async function loopRegistrationDetect() {
  if (!regVideo.srcObject) return; // stopped
  try {
    // try TFD first (fast)
    let det = await faceapi
      .detectSingleFace(regVideo, new faceapi.TinyFaceDetectorOptions({ inputSize: 416, scoreThreshold: 0.35 }))
      .withFaceLandmarks()
      .withFaceDescriptor();

    // fallback to SSD if we didn‚Äôt get a good descriptor
    if (!det || !det.descriptor || Number.isNaN(det.descriptor[0])) {
      det = await faceapi
        .detectSingleFace(regVideo, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.35, maxResults: 1 }))
        .withFaceLandmarks()
        .withFaceDescriptor();
    }

    regCtx.clearRect(0, 0, regOverlay.width, regOverlay.height);

    if (det) {
      const scaled = faceapi.resizeResults(det, { width: regOverlay.width, height: regOverlay.height });

      // draw face-hugging mask
      drawFaceMaskFromLandmarks(scaled.landmarks.positions, regCtx, regOverlay);

      // label
      const box = scaled.detection.box;
      regCtx.fillStyle = '#00ff88';
      regCtx.fillRect(box.x, Math.max(0, box.y - 20), Math.max(120, box.width), 18);
      regCtx.fillStyle = '#000';
      regCtx.font = 'bold 12px system-ui, Arial';
      regCtx.fillText('Face Detected ‚úì', box.x + 6, Math.max(12, box.y - 6));

      // collect descriptor while capture window active
      if (isRegistering && det.descriptor && !Number.isNaN(det.descriptor[0])) {
        regSamples.push(new Float32Array(det.descriptor));
      }
    } else {
      // light hint
      regCtx.fillStyle = 'rgba(0,0,0,.5)';
      regCtx.fillRect(0,0,regOverlay.width,regOverlay.height);
      regCtx.fillStyle = '#ff6666';
      regCtx.font = 'bold 14px system-ui, Arial';
      regCtx.textAlign = 'center';
      regCtx.fillText('Center your face ‚Ä¢ Good light ‚Ä¢ Look at camera', regOverlay.width/2, regOverlay.height - 10);
      regCtx.textAlign = 'left';
    }

    // update counter
    if (isRegistering) {
      qs('#samplesCounter').textContent = `Samples: ${regSamples.length}`;
    }
  } catch (e) {
    // ignore occasional decode slips
  }
  requestAnimationFrame(loopRegistrationDetect);
}

async function completeRegistration() {
  const status = qs('#registrationStatus');
  isRegistering = false;
  qs('#captureWrap').style.display = 'none';
  qs('#stopRegistration').style.display = 'none';
  qs('#startRegistration').style.display = 'inline-block';

  const samples = regSamples.length;
  if (samples < 3) {
    setStatus(status, `Only ${samples} face sample(s) captured. Try again with better lighting and keep your face centered.`, 'error');
    return;
  }

  // de-dup very similar vectors to keep diversity
  const src = regSamples;
  const unique = src.filter((d, i) => i === 0 || !src.slice(0,i).some(p => faceapi.euclideanDistance(d, p) < 0.12));
  if (unique.length < 3) {
    setStatus(status, `Only ${unique.length} unique sample(s). Move your head slightly and try again.`, 'error');
    return;
  }

  setStatus(status, `Processing ${unique.length} samples‚Ä¶`, 'info');

  try {
    const payload = unique.map(d => Array.from(d));
    const name = qs('#regName').value.trim();
    const resp = await fetch('/api/register', {
      method: 'POST',
      headers: { 'Content-Type':'application/json' },
      body: JSON.stringify({ name, descriptors: payload })
    });
    const result = await resp.json();
    if (!resp.ok) throw new Error(result?.error || 'Registration failed');

    setStatus(status, `Registration successful! ${name} saved with ${unique.length} samples.`, 'success');
    qs('#regName').value = '';
    qs('#samplesCounter').style.display = 'none';
    // detach stream from reg video (keeps main view alive)
    regVideo.srcObject = null; regVideo.style.display = 'none'; regOverlay.style.display = 'none';
  } catch (e) {
    console.error(e);
    setStatus(status, e.message || 'Registration failed. Please try again.', 'error');
  }
}

/* -------------------- Wire up -------------------- */
document.addEventListener('DOMContentLoaded', async () => {
  // elements
  mainVideo = qs('#mainVideo'); mainOverlay = qs('#mainOverlay'); mainCtx = mainOverlay.getContext('2d');
  regVideo  = qs('#regVideo');  regOverlay  = qs('#regOverlay');  regCtx  = regOverlay.getContext('2d');

  // models + cameras
  try {
    await loadModels();
  } catch (e) {
    qs('#liveInfo').textContent = 'Failed to load models. Check network / HTTPS.';
    return;
  }
  await listCameras();

  // start live view
  await startLive();

  // controls
  qs('#cameraSelect').addEventListener('change', async (e) => {
    currentCam = parseInt(e.target.value);
    await startLive();
  });
  qs('#flipCam').addEventListener('click', async () => {
    if (cameras.length > 1) {
      currentCam = (currentCam + 1) % cameras.length;
      qs('#cameraSelect').value = currentCam;
      await startLive();
    }
  });

  // registration buttons
  qs('#startRegistration').addEventListener('click', startRegistrationFlow);
  qs('#stopRegistration').addEventListener('click', stopRegistrationFlow);
});
</script>
</body>
</html>
